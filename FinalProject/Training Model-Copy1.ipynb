{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From /home/gmo/Documents/EE240/FinalProject/agent.py:40: to_float (from tensorflow.python.ops.math_ops) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.cast` instead.\n",
      "WARNING:tensorflow:From /home/gmo/Documents/EE240/FinalProject/agent.py:43: conv2d (from tensorflow.python.layers.convolutional) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use `tf.keras.layers.Conv2D` instead.\n",
      "WARNING:tensorflow:From /home/gmo/.local/lib/python3.5/site-packages/tensorflow/python/layers/convolutional.py:424: Layer.apply (from tensorflow.python.keras.engine.base_layer_v1) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Please use `layer.__call__` method instead.\n",
      "WARNING:tensorflow:From /home/gmo/.local/lib/python3.5/site-packages/tensorflow/python/ops/resource_variable_ops.py:1666: calling BaseResourceVariable.__init__ (from tensorflow.python.ops.resource_variable_ops) with constraint is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "If using Keras pass *_constraint arguments to layers.\n",
      "WARNING:tensorflow:From /home/gmo/Documents/EE240/FinalProject/agent.py:46: flatten (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Flatten instead.\n",
      "WARNING:tensorflow:From /home/gmo/Documents/EE240/FinalProject/agent.py:47: dense (from tensorflow.python.layers.core) is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Use keras.layers.Dense instead.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/gmo/.local/lib/python3.5/site-packages/gym_super_mario_bros/smb_env.py:148: RuntimeWarning: overflow encountered in ubyte_scalars\n",
      "  return (self.ram[0x86] - self.ram[0x071c]) % 256\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Episode 0 - Frame 233 - Frames/sec 139.0 - Epsilon 0.9999 - Mean Reward 2.665236051502146\n",
      "Episode 100 - Frame 43537 - Frames/sec 143.0 - Epsilon 0.9892 - Mean Reward 3.1668371964098183\n",
      "Episode 200 - Frame 85520 - Frames/sec 142.0 - Epsilon 0.9788 - Mean Reward 3.163144960939203\n",
      "Episode 300 - Frame 129298 - Frames/sec 84.0 - Epsilon 0.9682 - Mean Reward 3.1623640414451097\n",
      "Episode 400 - Frame 166310 - Frames/sec 70.0 - Epsilon 0.9593 - Mean Reward 3.409637260533143\n",
      "Episode 500 - Frame 204562 - Frames/sec 69.0 - Epsilon 0.9501 - Mean Reward 3.5032590715005165\n",
      "Episode 600 - Frame 245780 - Frames/sec 69.0 - Epsilon 0.9404 - Mean Reward 3.2047334949284334\n",
      "Episode 700 - Frame 286977 - Frames/sec 69.0 - Epsilon 0.9308 - Mean Reward 3.2198258884503734\n",
      "Episode 800 - Frame 324685 - Frames/sec 70.0 - Epsilon 0.922 - Mean Reward 3.467922920466985\n",
      "Episode 900 - Frame 368352 - Frames/sec 71.0 - Epsilon 0.912 - Mean Reward 3.26133360310438\n",
      "Episode 1000 - Frame 404003 - Frames/sec 70.0 - Epsilon 0.9039 - Mean Reward 3.3581039401270214\n",
      "Episode 1100 - Frame 447246 - Frames/sec 70.0 - Epsilon 0.8942 - Mean Reward 3.3409185760360653\n",
      "Episode 1200 - Frame 488852 - Frames/sec 70.0 - Epsilon 0.885 - Mean Reward 3.4065693743633476\n",
      "Episode 1300 - Frame 521405 - Frames/sec 70.0 - Epsilon 0.8778 - Mean Reward 3.656807994308787\n",
      "Episode 1400 - Frame 558049 - Frames/sec 70.0 - Epsilon 0.8698 - Mean Reward 3.740507275679187\n",
      "Episode 1500 - Frame 597381 - Frames/sec 70.0 - Epsilon 0.8613 - Mean Reward 3.4463885549845292\n",
      "Episode 1600 - Frame 631146 - Frames/sec 70.0 - Epsilon 0.854 - Mean Reward 3.5494429913030814\n",
      "Episode 1700 - Frame 675343 - Frames/sec 70.0 - Epsilon 0.8446 - Mean Reward 3.4877024104342467\n",
      "Episode 1800 - Frame 706087 - Frames/sec 71.0 - Epsilon 0.8382 - Mean Reward 3.9593640913452477\n",
      "Episode 1900 - Frame 741141 - Frames/sec 69.0 - Epsilon 0.8309 - Mean Reward 3.806011176728112\n",
      "Episode 2000 - Frame 780228 - Frames/sec 69.0 - Epsilon 0.8228 - Mean Reward 3.6775520989205126\n",
      "Episode 2100 - Frame 809771 - Frames/sec 69.0 - Epsilon 0.8167 - Mean Reward 3.704720289409286\n"
     ]
    }
   ],
   "source": [
    "import time\n",
    "import numpy as np\n",
    "from nes_py.wrappers import JoypadSpace\n",
    "import gym_super_mario_bros\n",
    "from gym_super_mario_bros.actions import SIMPLE_MOVEMENT\n",
    "from agent import DQNAgent\n",
    "from wrappers import wrapper\n",
    "\n",
    "\n",
    "# Build env (first level, right only)\n",
    "env = gym_super_mario_bros.make('SuperMarioBros-1-1-v0')\n",
    "env = JoypadSpace(env, SIMPLE_MOVEMENT)\n",
    "env = wrapper(env)\n",
    "\n",
    "# Parameters\n",
    "states = (84, 84, 4)\n",
    "actions = env.action_space.n\n",
    "\n",
    "# Agent\n",
    "agent = DQNAgent(states=states, actions=actions, max_memory=100000, double_q=True)\n",
    "\n",
    "# Episodes\n",
    "episodes = 10000\n",
    "rewards = []\n",
    "\n",
    "# Timing\n",
    "start = time.time()\n",
    "step = 0\n",
    "\n",
    "# Main loop\n",
    "for e in range(episodes):\n",
    "\n",
    "    # Reset env\n",
    "    state = env.reset()\n",
    "\n",
    "    # Reward\n",
    "    total_reward = 0\n",
    "    iter = 0\n",
    "\n",
    "    # Play\n",
    "    while True:\n",
    "\n",
    "        # Show env\n",
    "        # env.render()\n",
    "\n",
    "        # Run agent\n",
    "        action = agent.run(state=state)\n",
    "\n",
    "        # Perform action\n",
    "        next_state, reward, done, info = env.step(action=action)\n",
    "\n",
    "        # Remember\n",
    "        agent.add(experience=(state, next_state, action, reward, done))\n",
    "\n",
    "        # Replay\n",
    "        agent.learn()\n",
    "\n",
    "        # Total reward\n",
    "        total_reward += reward\n",
    "\n",
    "        # Update state\n",
    "        state = next_state\n",
    "\n",
    "        # Increment\n",
    "        iter += 1\n",
    "\n",
    "        # If done break loop\n",
    "        if done or info['flag_get']:\n",
    "            break\n",
    "\n",
    "    # Rewards\n",
    "    rewards.append(total_reward / iter)\n",
    "\n",
    "    # Print\n",
    "    if e % 100 == 0:\n",
    "        print('Episode {e} - '\n",
    "              'Frame {f} - '\n",
    "              'Frames/sec {fs} - '\n",
    "              'Epsilon {eps} - '\n",
    "              'Mean Reward {r}'.format(e=e,\n",
    "                                       f=agent.step,\n",
    "                                       fs=np.round((agent.step - step) / (time.time() - start)),\n",
    "                                       eps=np.round(agent.eps, 4),\n",
    "                                       r=np.mean(rewards[-100:])))\n",
    "        start = time.time()\n",
    "        step = agent.step\n",
    "\n",
    "# Save rewards\n",
    "np.save('rewards.npy', rewards)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.save_model()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "agent.replay(env,'./newest_models/',1, plot=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
